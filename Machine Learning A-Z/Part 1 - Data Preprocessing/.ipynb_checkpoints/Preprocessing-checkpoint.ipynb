{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datasets\n",
    "import pandas as pd  # to import datasets and manage them\n",
    "import numpy as np   # for mathematical operations\n",
    "import matplotlib.pyplot as plt # for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "data = pd.read_csv('Data.csv')\n",
    "X = data.iloc[:,:-1].values # create array of features\n",
    "Y = data.iloc[:,-1].values  # prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "skl_mean = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "skl_mean.fit(X[:,1:3])\n",
    "X[:,1:3] = skl_mean.transform(X[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 6.10737882e-04\n",
      "  9.99389262e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 5.62183772e-04\n",
      "  9.99437816e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.55247085e-04\n",
      "  9.99444753e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 6.22562994e-04\n",
      "  9.99377437e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.26784595e-04\n",
      "  9.99373215e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.03084346e-04\n",
      "  9.99396916e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 7.45170802e-04\n",
      "  9.99254829e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.07225989e-04\n",
      "  9.99392774e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.02046960e-04\n",
      "  9.99397953e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 5.51934007e-04\n",
      "  9.99448066e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical variable\n",
    "# https://jorisvandenbossche.github.io/blog/2018/05/28/scikit-learn-columntransformer/\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, LabelEncoder\n",
    "columntransformer = make_column_transformer((OneHotEncoder(),[0]), (Normalizer(norm='l1'), [1,2]))\n",
    "X = columntransformer.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "Y = labelencoder.fit_transform(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 6.10737882e-04\n",
      "  9.99389262e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 5.62183772e-04\n",
      "  9.99437816e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.55247085e-04\n",
      "  9.99444753e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 6.22562994e-04\n",
      "  9.99377437e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.26784595e-04\n",
      "  9.99373215e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.03084346e-04\n",
      "  9.99396916e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 7.45170802e-04\n",
      "  9.99254829e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.07225989e-04\n",
      "  9.99392774e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.02046960e-04\n",
      "  9.99397953e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 5.51934007e-04\n",
      "  9.99448066e-01]]\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 6.10737882e-04\n",
      "  9.99389262e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.07225989e-04\n",
      "  9.99392774e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.55247085e-04\n",
      "  9.99444753e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 5.51934007e-04\n",
      "  9.99448066e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.26784595e-04\n",
      "  9.99373215e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 6.22562994e-04\n",
      "  9.99377437e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 7.45170802e-04\n",
      "  9.99254829e-01]]\n",
      "[0 1 0 1 1 0 0]\n",
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 6.02046960e-04\n",
      "  9.99397953e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 5.62183772e-04\n",
      "  9.99437816e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.03084346e-04\n",
      "  9.99396916e-01]]\n",
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the training set and test set\n",
    "print(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state = 42) # if you don't specify random_state, selection of test set is done at random.\n",
    "print(X_train)\n",
    "print(Y_train)\n",
    "print(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed x_train:  [[1.         0.         0.         0.30430993 0.69569007]\n",
      " [1.         0.         0.         0.28613589 0.71386411]\n",
      " [0.         1.         0.         0.01714517 0.98285483]\n",
      " [1.         0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.38735163 0.61264837]\n",
      " [0.         0.         1.         0.36550486 0.63449514]\n",
      " [0.         0.         1.         1.         0.        ]]\n",
      "[[0.         1.         0.         0.25933442 0.74066558]\n",
      " [0.         0.         1.         0.05304251 0.94695749]\n",
      " [1.         0.         0.         0.26470289 0.73529711]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "transformer = MinMaxScaler()\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "print('transformed x_train: ',X_train_1)\n",
    "X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
