{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datasets\n",
    "import pandas as pd  # to import datasets and manage them\n",
    "import numpy as np   # for mathematical operations\n",
    "import matplotlib.pyplot as plt # for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "data = pd.read_csv('Data.csv')\n",
    "X = data.iloc[:,:-1].values # create array of features\n",
    "Y = data.iloc[:,-1].values  # prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with missing data\n",
    "# remove the observations can be dangerous if it contains important information.\n",
    "# Replace the missing data with mean of the data\n",
    "# Impute means to infer them from the known parts of data.\n",
    "\n",
    "# from sklearn.preprocessing import Imputer # import Imputer class from the sklearn.preprocessing library \n",
    "# imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "# imputer = imputer.fit(X[:, 1:3])\n",
    "# X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# skl_mean = SimpleImputer(missing_values = np.nan, strategy = 'constant', fill_value = 1)\n",
    "skl_mean = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "skl_mean.fit(X[:,1:3])\n",
    "X[:,1:3] = skl_mean.transform(X[:,1:3])\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variable\n",
    "# Deprecated\n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# labelencoder = LabelEncoder()\n",
    "# X[:,0] = labelencoder.fit_transform(X[:,0])\n",
    "# print(X)\n",
    "# onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "# X = onehotencoder.fit_transform(X).toarray()\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 6.10737882e-04\n",
      "  9.99389262e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 5.62183772e-04\n",
      "  9.99437816e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.55247085e-04\n",
      "  9.99444753e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 6.22562994e-04\n",
      "  9.99377437e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.26784595e-04\n",
      "  9.99373215e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.03084346e-04\n",
      "  9.99396916e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 7.45170802e-04\n",
      "  9.99254829e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.07225989e-04\n",
      "  9.99392774e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.02046960e-04\n",
      "  9.99397953e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 5.51934007e-04\n",
      "  9.99448066e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical variable\n",
    "# https://jorisvandenbossche.github.io/blog/2018/05/28/scikit-learn-columntransformer/\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, LabelEncoder\n",
    "# columntransformer = ColumnTransformer([\"encode\",OneHotEncoder(categories = ['France', 'Spain', 'Germany']),[0,1,2]])\n",
    "# columntransformer.fit_transform(X[:,0])\n",
    "# print(X)\n",
    "# onehotencoder = OneHotEncoder()\n",
    "# inputs should be transformer, columns \n",
    "columntransformer = make_column_transformer((OneHotEncoder(),[0]), (Normalizer(norm='l1'), [1,2]))\n",
    "X = columntransformer.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "Y = labelencoder.fit_transform(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 6.10737882e-04\n",
      "  9.99389262e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 5.62183772e-04\n",
      "  9.99437816e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.55247085e-04\n",
      "  9.99444753e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 6.22562994e-04\n",
      "  9.99377437e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.26784595e-04\n",
      "  9.99373215e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.03084346e-04\n",
      "  9.99396916e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 7.45170802e-04\n",
      "  9.99254829e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.07225989e-04\n",
      "  9.99392774e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.02046960e-04\n",
      "  9.99397953e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 5.51934007e-04\n",
      "  9.99448066e-01]]\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 6.10737882e-04\n",
      "  9.99389262e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.07225989e-04\n",
      "  9.99392774e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.55247085e-04\n",
      "  9.99444753e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 5.51934007e-04\n",
      "  9.99448066e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 6.26784595e-04\n",
      "  9.99373215e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 6.22562994e-04\n",
      "  9.99377437e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 7.45170802e-04\n",
      "  9.99254829e-01]]\n",
      "[0 1 0 1 1 0 0]\n",
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 6.02046960e-04\n",
      "  9.99397953e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 5.62183772e-04\n",
      "  9.99437816e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 6.03084346e-04\n",
      "  9.99396916e-01]]\n",
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the training set and test set\n",
    "print(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state = 42) # if you don't specify random_state, selection of test set is done at random.\n",
    "print(X_train)\n",
    "print(Y_train)\n",
    "print(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed x_train:  [[1.         0.         0.         0.30430993 0.69569007]\n",
      " [1.         0.         0.         0.28613589 0.71386411]\n",
      " [0.         1.         0.         0.01714517 0.98285483]\n",
      " [1.         0.         0.         0.         1.        ]\n",
      " [0.         1.         0.         0.38735163 0.61264837]\n",
      " [0.         0.         1.         0.36550486 0.63449514]\n",
      " [0.         0.         1.         1.         0.        ]]\n",
      "[[0.         1.         0.         0.25933442 0.74066558]\n",
      " [0.         0.         1.         0.05304251 0.94695749]\n",
      " [1.         0.         0.         0.26470289 0.73529711]]\n"
     ]
    }
   ],
   "source": [
    "# \"normalization\" typically means that the range of values are \"normalized to be from 0.0 to 1.0\". \"Standardization\" typically means that the range of values are \"standardized\" to measure how many standard deviations the value is from its mean.\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "transformer = MinMaxScaler()\n",
    "X_train_1 = transformer.fit_transform(X_train)\n",
    "print('transformed x_train: ',X_train_1)\n",
    "X_test_1 = transformer.transform(X_test)\n",
    "print(X_test_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
